# ğŸ§  Sentiment Analyzer â€“ Powered by Mistral & Ollama ğŸš€

Welcome to the **next-generation** Sentiment Analysis app â€“ crafted with precision, speed, and elegance.  
This AI-powered tool leverages the **Mistral model** via **Ollama**, delivering lightning-fast, highly accurate sentiment classification with a beautiful UI and rock-solid backend.

> ğŸŒŸ Built for innovators, by an innovator. If youâ€™re reading this, youâ€™re looking at a project from the **top 1%**.

---

## âœ¨ Features That Set It Apart
- âš¡ **Blazing-Fast Predictions** â€“ Mistral model optimized via Ollama for near-instant responses.
- ğŸ–¥ **Modern Two-Tier Architecture** â€“ FastAPI backend + Streamlit frontend.
- ğŸ¤– **AI-Powered Accuracy** â€“ Understands context, tone, and emotional polarity.
- ğŸ“¦ **Lightweight & Portable** â€“ Easy to set up, run, and extend.
- ğŸ”„ **Seamless Integration** â€“ Ready to plug into larger systems or use as a standalone app.

---

## ğŸ— Tech Stack
| Layer           | Technology |
|-----------------|------------|
| **Frontend**    | Streamlit  |
| **Backend**     | FastAPI    |
| **Model Host**  | Ollama (Mistral) |
| **Language**    | Python     |
| **Versioning**  | Git + GitHub |

---

## ğŸš€ How It Works
1. **User Input** â†’ You enter any sentence into the sleek Streamlit UI.
2. **API Call** â†’ FastAPI sends the text to Ollama's Mistral model.
3. **AI Processing** â†’ Mistral analyzes and classifies the sentiment: **Positive**, **Negative**, or **Neutral**.
4. **Results Displayed** â†’ The prediction is shown instantly on the UI.

---

## ğŸ“¸ Working Screenshot
[**Click Here to View**](https://drive.google.com/drive/folders/14O7rp1lcw_7dJt3Hpmj6tu7b9sC3RgMV?usp=sharing)

---

## ğŸ›  Quick Start â€“ Run Locally

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/mrflint5/sentiment-analyzer-mistral.git
cd sentiment-analyzer-mistral
```

### 2ï¸âƒ£ Set Up Virtual Environment
```bash
python -m venv venv
```
- **Windows**:
```bash
venv\Scripts\activate
```
- **Mac/Linux**:
```bash
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Pull the Mistral Model (Ensure Ollama is running)
```bash
ollama pull mistral
```

### 5ï¸âƒ£ Run Backend (FastAPI)
```bash
uvicorn backend.main:app --reload
```

### 6ï¸âƒ£ Run Frontend (Streamlit)
```bash
streamlit run frontend/app.py
```

---

## ğŸ“‚ Project Structure
```
sentiment-analyzer-mistral/
â”‚
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py          # FastAPI backend code
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py           # Streamlit frontend code
â”‚
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # This file
```

---

## ğŸ’¡ Pro Tip
This project is **modular** â€“ swap Mistral with any Ollama-supported LLM to experiment with different language models without changing your core logic.

---

## ğŸ¤ Contributing
Pull requests are welcome! If you have ideas to push this project beyond its limits, letâ€™s make it happen.

---

## ğŸŒ Connect With Me
- **LinkedIn**: [Sameer Malik](https://www.linkedin.com/in/sameer-malik-b5b8772b9)
- **Email**: sameermalik1419@gmail.com

> ğŸ† Remember: Good code solves problems, but **great code inspires innovation**.
